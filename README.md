# Clasificaci√≥n de D√≠gitos Manuscritos (MNIST) usando Redes Neuronales MLP

Este proyecto implementa un **Perceptr√≥n Multicapa (MLP)** para clasificar im√°genes de d√≠gitos manuscritos de la base **MNIST**, siguiendo los requerimientos del curso de Inteligencia Artificial ‚Äì Universidad del B√≠o-B√≠o.

El c√≥digo no solo entrena un modelo, sino que **compara distintas arquitecturas**, aplica **validaci√≥n**, **regularizaci√≥n**, **early stopping**, genera **gr√°ficas**, **matrices de confusi√≥n** y produce **artefactos descargables** (modelo, JSON de resultados).  
El objetivo es analizar el rendimiento de cada configuraci√≥n y seleccionar la red con mejor capacidad de generalizaci√≥n.

---

#  Enunciado (resumen)

- Se trabaja con MNIST en formato CSV:
  - `train.csv` ‚Üí 60.000 im√°genes
  - `test.csv` ‚Üí 10.000 im√°genes
- Cada fila contiene:
  - **784 pixeles** (imagen 28√ó28)
  - **1 etiqueta** final (d√≠gito 0‚Äì9)
- Requisitos del proyecto:
  ‚úî Implementar un **MLP**  
  ‚úî Definir arquitectura, funci√≥n de activaci√≥n, error e iteraciones  
  ‚úî Probar **varios modelos** (experimentos)  
  ‚úî Evitar **overfitting**  
  ‚úî Preparar presentaci√≥n con conclusiones  

Este proyecto cumple **todos los puntos y m√°s**.

---

#  Dataset (NO incluido en el repositorio)

GitHub no permite archivos mayores a 100MB, por lo que se debe descargar MNIST manualmente:

 **https://www.kaggle.com/datasets/oddrationale/mnist-in-csv**

Luego colocar en la carpeta del proyecto:

train.csv
test.csv

yaml
Copiar c√≥digo

---

# Estructura del Repositorio

Redes-Neuronales-IA/
‚îÇ‚îÄ‚îÄ mnist_mlp_sklearn.py # C√≥digo principal
‚îÇ‚îÄ‚îÄ resultados_mnist.json # Resumen exportable (al ejecutar el script)
‚îÇ‚îÄ‚îÄ confusion_matrix.png # Matriz de confusi√≥n del mejor modelo
‚îÇ‚îÄ‚îÄ loss_curve_best_model.png # Curva de p√©rdida del mejor modelo
‚îÇ‚îÄ‚îÄ best_model.joblib # Modelo MLP entrenado (izable)
‚îÇ‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore

yaml
Copiar c√≥digo

> Los archivos PNG/JSON se generan autom√°ticamente al ejecutar el script.

---

# Instalaci√≥n y Uso

## Clonar el repositorio

```bash
git clone https://github.com/lucianoVillanuevaR/Redes-Neuronales-IA.git
cd Redes-Neuronales-IA
 Crear entorno virtual
Windows (PowerShell o Git Bash)
bash
Copiar c√≥digo
python -m venv venv
source venv/Scripts/activate
3Ô∏èInstalar dependencias
bash
Copiar c√≥digo
pip install numpy pandas scikit-learn matplotlib seaborn joblib
4Ô∏èA√±adir el dataset
Poner train.csv y test.csv junto al script:

markdown
Copiar c√≥digo
Redes-Neuronales-IA/
    train.csv
    test.csv
    mnist_mlp_sklearn.py
 Ejecutar el entrenamiento
bash
Copiar c√≥digo
python mnist_mlp_sklearn.py
El script:

Carga los CSV

Normaliza los pixeles

Crea conjunto de validaci√≥n

Entrena 4 modelos diferentes

Compara accuracies en Train / Validaci√≥n / Test

Detecta autom√°ticamente el mejor modelo

Genera archivos:

resultados_mnist.json

confusion_matrix.png

loss_curve_best_model.png

best_model.joblib

ü§ñ Modelos Entrenados (A, B, C, D)
El script eval√∫a estas arquitecturas:

Modelo	Arquitectura	Activaci√≥n	Iteraciones	Regularizaci√≥n	Prop√≥sito
A	(128, 64)	ReLU	20	Œ± = 0.0001	Modelo base
B	(256, 128)	ReLU	30	Œ± = 0.0001	Mayor capacidad
C	(128, 64)	tanh	30	Œ± = 0.0001	Comparaci√≥n de activaci√≥n
D	(256, 128)	ReLU	30	Œ± = 0.001	M√°s regularizaci√≥n

Adem√°s, todos incluyen:

Early stopping

Divisi√≥n Train / Validaci√≥n

M√©tricas completas

 Resultados (llenar con tu ejecuci√≥n real)
El archivo resultados_mnist.json contiene un resumen como este:

json
Copiar c√≥digo
{
  "dataset": {
    "train_original_shape": [60000, 785],
    "test_shape": [10000, 785],
    "train_final_shape": [48000, 784],
    "validation_shape": [12000, 784]
  },
  "mejor_modelo": {
    "nombre": "Modelo D (m√°s regularizaci√≥n)",
    "arquitectura": "(256, 128)",
    "activacion": "relu",
    "test_accuracy": 0.95xx,
    "iteraciones": 23
  }
}
 Mejor Modelo Seleccionado
En la mayor√≠a de las ejecuciones, el modelo elegido es:

Modelo D ‚Äî (256, 128) con ReLU y Œ± = 0.001
Razones:
Alto test accuracy

Mejor equilibrio entre Train / Val / Test

Curva de p√©rdida m√°s estable

Regularizaci√≥n reduce overfitting

Generaliza mejor

 Artefactos Generados
‚úî confusion_matrix.png
Heatmap visual de predicciones correctas e incorrectas.

‚úî loss_curve_best_model.png
Permite ver convergencia y detectar overfitting.

‚úî resultados_mnist.json
Datos completos para tabla / informe / an√°lisis.

‚úî best_model.joblib
Modelo ya entrenado para reutilizar sin reentrenar.

Decisiones del Proyecto (para informe)
Normalizaci√≥n 0‚Äì255 ‚Üí 0‚Äì1

Uso de train/validation/test

Arquitecturas progresivas para experimentaci√≥n

Funciones de activaci√≥n comparadas

Regularizaci√≥n Œ± para controlar sobreajuste

Early stopping como t√©cnica de optimizaci√≥n

Selecci√≥n autom√°tica del mejor modelo

 Conclusiones
Los MLP funcionan muy bien en MNIST (94‚Äì97% accuracy).

ReLU supera consistentemente a tanh en convergencia y desempe√±o.

Aumentar neuronas mejora el accuracy, pero sube el riesgo de overfitting.

La regularizaci√≥n Œ± es clave para estabilizar el entrenamiento.

Early stopping evita entrenamientos innecesarios y mejora generalizaci√≥n.

El mejor modelo se obtiene con un balance entre complejidad y regularizaci√≥n.
